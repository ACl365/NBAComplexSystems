{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NBA Player Performance Dynamics: Network Analysis\n",
    "\n",
    "This notebook applies network analysis to understand teammate interactions, identify performance multipliers, and develop a comprehensive player impact framework that integrates production, stability, adaptability, and network metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import networkx as nx\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Add the project root to the path so we can import our modules\n",
    "sys.path.append('..')\n",
    "\n",
    "# Import our modules\n",
    "from src.network_analysis import (\n",
    "    build_teammate_network,\n",
    "    calculate_network_metrics,\n",
    "    identify_synergy_pairs,\n",
    "    calculate_network_value\n",
    ")\n",
    "from src.visualization import create_network_visualization\n",
    "from src.utils import setup_plotting_style\n",
    "\n",
    "# Set up plotting style\n",
    "setup_plotting_style()\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Processed Data\n",
    "\n",
    "Let's load the processed data from previous notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the processed data\n",
    "try:\n",
    "    player_dynamics = pd.read_csv('../data/processed/player_dynamics.csv')\n",
    "    player_team_fit = pd.read_csv('../data/processed/player_team_fit.csv')\n",
    "    player_temporal_df = pd.read_csv('../data/processed/player_temporal.csv')\n",
    "    games_processed = pd.read_csv('../data/processed/games_processed.csv')\n",
    "    \n",
    "    # Convert date strings to datetime objects\n",
    "    player_temporal_df['GAME_DATE'] = pd.to_datetime(player_temporal_df['GAME_DATE'])\n",
    "    games_processed['GAME_DATE'] = pd.to_datetime(games_processed['GAME_DATE'])\n",
    "    \n",
    "    print(f\"Loaded player dynamics data with {len(player_dynamics)} players\")\n",
    "    print(f\"Loaded player team fit data with {len(player_team_fit)} players\")\n",
    "    print(f\"Loaded player temporal data with {len(player_temporal_df)} records\")\n",
    "    print(f\"Loaded processed games data with {len(games_processed)} records\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Processed data not found. Please run the previous notebooks first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the player dynamics data\n",
    "player_dynamics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the player team fit data\n",
    "player_team_fit.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teammate Network Construction\n",
    "\n",
    "Let's build a network of teammate interactions based on game data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify teammates for each game\n",
    "# Group player game data by game and team\n",
    "teammates_by_game = {}\n",
    "\n",
    "for game_id in player_temporal_df['Game_ID'].unique():\n",
    "    game_data = player_temporal_df[player_temporal_df['Game_ID'] == game_id]\n",
    "    \n",
    "    # Group by team\n",
    "    for team_id in game_data['Team_ID'].unique():\n",
    "        team_players = game_data[game_data['Team_ID'] == team_id]\n",
    "        \n",
    "        # Get player IDs\n",
    "        player_ids = team_players['Player_ID'].tolist()\n",
    "        \n",
    "        # Add to teammates dictionary\n",
    "        if game_id not in teammates_by_game:\n",
    "            teammates_by_game[game_id] = {}\n",
    "        \n",
    "        teammates_by_game[game_id][team_id] = player_ids\n",
    "\n",
    "# Count number of games with teammate data\n",
    "print(f\"Identified teammates for {len(teammates_by_game)} games\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build teammate frequency matrix\n",
    "player_ids = player_dynamics['player_id'].unique()\n",
    "n_players = len(player_ids)\n",
    "\n",
    "# Create a dictionary to map player IDs to indices\n",
    "player_to_idx = {player_id: i for i, player_id in enumerate(player_ids)}\n",
    "idx_to_player = {i: player_id for i, player_id in enumerate(player_ids)}\n",
    "\n",
    "# Initialize teammate frequency matrix\n",
    "teammate_freq = np.zeros((n_players, n_players))\n",
    "\n",
    "# Fill the matrix\n",
    "for game_id, teams in teammates_by_game.items():\n",
    "    for team_id, players in teams.items():\n",
    "        # For each pair of teammates\n",
    "        for i, player1 in enumerate(players):\n",
    "            if player1 in player_to_idx:  # Check if player is in our player list\n",
    "                idx1 = player_to_idx[player1]\n",
    "                for player2 in players[i+1:]:\n",
    "                    if player2 in player_to_idx:  # Check if player is in our player list\n",
    "                        idx2 = player_to_idx[player2]\n",
    "                        # Increment frequency for both directions\n",
    "                        teammate_freq[idx1, idx2] += 1\n",
    "                        teammate_freq[idx2, idx1] += 1\n",
    "\n",
    "# Create a dataframe with player names for easier interpretation\n",
    "player_names = {}\n",
    "for player_id in player_ids:\n",
    "    player_name = player_dynamics[player_dynamics['player_id'] == player_id]['player_name'].iloc[0]\n",
    "    player_names[player_id] = player_name\n",
    "\n",
    "# Print some statistics about the teammate frequency matrix\n",
    "print(f\"Teammate frequency matrix shape: {teammate_freq.shape}\")\n",
    "print(f\"Maximum teammate frequency: {np.max(teammate_freq)}\")\n",
    "print(f\"Average teammate frequency: {np.mean(teammate_freq)}\")\n",
    "print(f\"Number of non-zero entries: {np.count_nonzero(teammate_freq)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build correlation-based influence network\n",
    "# For each pair of teammates, calculate the correlation between their plus/minus\n",
    "influence_matrix = np.zeros((n_players, n_players))\n",
    "\n",
    "# For each player pair\n",
    "for i in range(n_players):\n",
    "    player1_id = idx_to_player[i]\n",
    "    player1_games = player_temporal_df[player_temporal_df['Player_ID'] == player1_id]\n",
    "    \n",
    "    for j in range(i+1, n_players):\n",
    "        player2_id = idx_to_player[j]\n",
    "        player2_games = player_temporal_df[player_temporal_df['Player_ID'] == player2_id]\n",
    "        \n",
    "        # Find common games\n",
    "        common_games = set(player1_games['Game_ID']).intersection(set(player2_games['Game_ID']))\n",
    "        \n",
    "        # If they have enough common games\n",
    "        if len(common_games) >= 10:  # Minimum number of common games\n",
    "            # Get plus/minus for common games\n",
    "            player1_pm = player1_games[player1_games['Game_ID'].isin(common_games)]['PLUS_MINUS'].values\n",
    "            player2_pm = player2_games[player2_games['Game_ID'].isin(common_games)]['PLUS_MINUS'].values\n",
    "            \n",
    "            # Calculate correlation\n",
    "            corr = np.corrcoef(player1_pm, player2_pm)[0, 1]\n",
    "            \n",
    "            # Store correlation in influence matrix\n",
    "            influence_matrix[i, j] = corr\n",
    "            influence_matrix[j, i] = corr\n",
    "\n",
    "# Replace NaN values with 0\n",
    "influence_matrix = np.nan_to_num(influence_matrix)\n",
    "\n",
    "# Print some statistics about the influence matrix\n",
    "print(f\"Influence matrix shape: {influence_matrix.shape}\")\n",
    "print(f\"Maximum influence: {np.max(influence_matrix)}\")\n",
    "print(f\"Minimum influence: {np.min(influence_matrix)}\")\n",
    "print(f\"Average influence: {np.mean(influence_matrix)}\")\n",
    "print(f\"Number of non-zero entries: {np.count_nonzero(influence_matrix)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create network visualizations\n",
    "# Convert matrices to NetworkX graphs\n",
    "# Teammate frequency network\n",
    "G_freq = nx.Graph()\n",
    "\n",
    "# Add nodes\n",
    "for i in range(n_players):\n",
    "    player_id = idx_to_player[i]\n",
    "    player_name = player_names[player_id]\n",
    "    G_freq.add_node(i, name=player_name, id=player_id)\n",
    "\n",
    "# Add edges with weight based on frequency\n",
    "for i in range(n_players):\n",
    "    for j in range(i+1, n_players):\n",
    "        if teammate_freq[i, j] > 0:  # Only add edges for players who have been teammates\n",
    "            G_freq.add_edge(i, j, weight=teammate_freq[i, j])\n",
    "\n",
    "# Influence network\n",
    "G_influence = nx.Graph()\n",
    "\n",
    "# Add nodes\n",
    "for i in range(n_players):\n",
    "    player_id = idx_to_player[i]\n",
    "    player_name = player_names[player_id]\n",
    "    G_influence.add_node(i, name=player_name, id=player_id)\n",
    "\n",
    "# Add edges with weight based on influence\n",
    "for i in range(n_players):\n",
    "    for j in range(i+1, n_players):\n",
    "        if influence_matrix[i, j] > 0.3:  # Only add edges for significant positive influence\n",
    "            G_influence.add_edge(i, j, weight=influence_matrix[i, j])\n",
    "\n",
    "# Print network statistics\n",
    "print(f\"Teammate frequency network: {G_freq.number_of_nodes()} nodes, {G_freq.number_of_edges()} edges\")\n",
    "print(f\"Influence network: {G_influence.number_of_nodes()} nodes, {G_influence.number_of_edges()} edges\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the influence network\n",
    "# Extract the largest connected component for better visualization\n",
    "largest_cc = max(nx.connected_components(G_influence), key=len)\n",
    "G_influence_cc = G_influence.subgraph(largest_cc).copy()\n",
    "\n",
    "# Calculate node sizes based on degree centrality\n",
    "degree_centrality = nx.degree_centrality(G_influence_cc)\n",
    "node_sizes = [5000 * degree_centrality[node] + 100 for node in G_influence_cc.nodes()]\n",
    "\n",
    "# Calculate edge widths based on weight\n",
    "edge_widths = [2 * G_influence_cc[u][v]['weight'] for u, v in G_influence_cc.edges()]\n",
    "\n",
    "# Create a spring layout\n",
    "pos = nx.spring_layout(G_influence_cc, seed=42)\n",
    "\n",
    "# Create the visualization\n",
    "plt.figure(figsize=(12, 12))\n",
    "nx.draw_networkx_nodes(G_influence_cc, pos, node_size=node_sizes, alpha=0.7, node_color='skyblue')\n",
    "nx.draw_networkx_edges(G_influence_cc, pos, width=edge_widths, alpha=0.5, edge_color='gray')\n",
    "nx.draw_networkx_labels(G_influence_cc, pos, labels={node: G_influence_cc.nodes[node]['name'] for node in G_influence_cc.nodes()})\n",
    "\n",
    "plt.title('Player Influence Network (Largest Connected Component)', fontsize=14)\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting the Teammate Network\n",
    "\n",
    "The teammate network visualization reveals several interesting patterns:\n",
    "\n",
    "1. **Network Structure**: [Observations about the network structure based on your visualization]\n",
    "2. **Central Players**: [Observations about central players based on your visualization]\n",
    "3. **Player Clusters**: [Observations about player clusters based on your visualization]\n",
    "4. **Influence Relationships**: [Observations about influence relationships based on your visualization]\n",
    "\n",
    "These patterns provide insights into the social and performance dynamics of NBA teams, highlighting players who serve as connectors, influencers, or performance multipliers within the league."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Metrics Calculation\n",
    "\n",
    "Let's calculate network metrics to quantify player influence and centrality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate network metrics for each player\n",
    "network_metrics = []\n",
    "\n",
    "# Calculate centrality metrics for the influence network\n",
    "degree_centrality = nx.degree_centrality(G_influence)\n",
    "betweenness_centrality = nx.betweenness_centrality(G_influence)\n",
    "eigenvector_centrality = nx.eigenvector_centrality_numpy(G_influence, weight='weight')\n",
    "pagerank = nx.pagerank(G_influence, weight='weight')\n",
    "\n",
    "# Calculate average influence\n",
    "avg_influence = {}\n",
    "for i in range(n_players):\n",
    "    # Get non-zero influences\n",
    "    influences = influence_matrix[i, :]\n",
    "    non_zero = influences[influences != 0]\n",
    "    if len(non_zero) > 0:\n",
    "        avg_influence[i] = np.mean(non_zero)\n",
    "    else:\n",
    "        avg_influence[i] = 0\n",
    "\n",
    "# Calculate positive influence count\n",
    "positive_influence_count = {}\n",
    "for i in range(n_players):\n",
    "    positive_influence_count[i] = np.sum(influence_matrix[i, :] > 0.3)  # Count significant positive influences\n",
    "\n",
    "# Combine metrics for each player\n",
    "for i in range(n_players):\n",
    "    player_id = idx_to_player[i]\n",
    "    player_name = player_names[player_id]\n",
    "    \n",
    "    network_metrics.append({\n",
    "        'player_id': player_id,\n",
    "        'player_name': player_name,\n",
    "        'degree_centrality': degree_centrality.get(i, 0),\n",
    "        'betweenness_centrality': betweenness_centrality.get(i, 0),\n",
    "        'eigenvector_centrality': eigenvector_centrality.get(i, 0),\n",
    "        'pagerank': pagerank.get(i, 0),\n",
    "        'avg_influence': avg_influence.get(i, 0),\n",
    "        'positive_influence_count': positive_influence_count.get(i, 0)\n",
    "    })\n",
    "\n",
    "# Convert to dataframe\n",
    "network_df = pd.DataFrame(network_metrics)\n",
    "\n",
    "# Sort by eigenvector centrality\n",
    "network_df = network_df.sort_values('eigenvector_centrality', ascending=False)\n",
    "\n",
    "# Display top players by network metrics\n",
    "network_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize network metrics distribution\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Degree centrality\n",
    "axes[0, 0].hist(network_df['degree_centrality'], bins=20, alpha=0.7, color='skyblue')\n",
    "axes[0, 0].set_xlabel('Degree Centrality', fontsize=12)\n",
    "axes[0, 0].set_ylabel('Number of Players', fontsize=12)\n",
    "axes[0, 0].set_title('Degree Centrality Distribution', fontsize=14)\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Eigenvector centrality\n",
    "axes[0, 1].hist(network_df['eigenvector_centrality'], bins=20, alpha=0.7, color='salmon')\n",
    "axes[0, 1].set_xlabel('Eigenvector Centrality', fontsize=12)\n",
    "axes[0, 1].set_ylabel('Number of Players', fontsize=12)\n",
    "axes[0, 1].set_title('Eigenvector Centrality Distribution', fontsize=14)\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Average influence\n",
    "axes[1, 0].hist(network_df['avg_influence'], bins=20, alpha=0.7, color='lightgreen')\n",
    "axes[1, 0].set_xlabel('Average Influence', fontsize=12)\n",
    "axes[1, 0].set_ylabel('Number of Players', fontsize=12)\n",
    "axes[1, 0].set_title('Average Influence Distribution', fontsize=14)\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Positive influence count\n",
    "axes[1, 1].hist(network_df['positive_influence_count'], bins=20, alpha=0.7, color='purple')\n",
    "axes[1, 1].set_xlabel('Positive Influence Count', fontsize=12)\n",
    "axes[1, 1].set_ylabel('Number of Players', fontsize=12)\n",
    "axes[1, 1].set_title('Positive Influence Count Distribution', fontsize=14)\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify top players by different network metrics\n",
    "top_degree = network_df.nlargest(5, 'degree_centrality')\n",
    "top_eigenvector = network_df.nlargest(5, 'eigenvector_centrality')\n",
    "top_betweenness = network_df.nlargest(5, 'betweenness_centrality')\n",
    "top_influence = network_df.nlargest(5, 'avg_influence')\n",
    "\n",
    "print(\"Top Players by Degree Centrality (Connectivity):\")\n",
    "print(top_degree[['player_name', 'degree_centrality']])\n",
    "\n",
    "print(\"\\nTop Players by Eigenvector Centrality (Influence):\")\n",
    "print(top_eigenvector[['player_name', 'eigenvector_centrality']])\n",
    "\n",
    "print(\"\\nTop Players by Betweenness Centrality (Bridge Players):\")\n",
    "print(top_betweenness[['player_name', 'betweenness_centrality']])\n",
    "\n",
    "print(\"\\nTop Players by Average Influence:\")\n",
    "print(top_influence[['player_name', 'avg_influence']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting Network Metrics\n",
    "\n",
    "The network metrics provide insights into different aspects of player influence and connectivity:\n",
    "\n",
    "1. **Degree Centrality**: Measures the number of direct connections a player has. Players with high degree centrality are well-connected and have played with many other players.\n",
    "   - Top players: [List top players from your data]\n",
    "\n",
    "2. **Eigenvector Centrality**: Measures influence by considering both the quantity and quality of connections. Players with high eigenvector centrality are connected to other influential players.\n",
    "   - Top players: [List top players from your data]\n",
    "\n",
    "3. **Betweenness Centrality**: Measures how often a player serves as a bridge between other players. Players with high betweenness centrality connect different groups or clusters of players.\n",
    "   - Top players: [List top players from your data]\n",
    "\n",
    "4. **Average Influence**: Measures the average correlation in plus/minus with teammates. Players with high average influence tend to have a positive impact on their teammates' performance.\n",
    "   - Top players: [List top players from your data]\n",
    "\n",
    "These metrics identify different types of influential players in the NBA, from connectors to performance multipliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify Synergy Pairs and Clusters\n",
    "\n",
    "Let's identify player pairs with strong synergy and clusters of players who work well together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify synergy pairs\n",
    "synergy_pairs = []\n",
    "\n",
    "# Threshold for significant synergy\n",
    "synergy_threshold = 0.5\n",
    "\n",
    "for i in range(n_players):\n",
    "    for j in range(i+1, n_players):\n",
    "        if influence_matrix[i, j] > synergy_threshold:  # Only consider strong positive influence\n",
    "            player1_id = idx_to_player[i]\n",
    "            player2_id = idx_to_player[j]\n",
    "            player1_name = player_names[player1_id]\n",
    "            player2_name = player_names[player2_id]\n",
    "            \n",
    "            synergy_pairs.append({\n",
    "                'player1_id': player1_id,\n",
    "                'player2_id': player2_id,\n",
    "                'player1_name': player1_name,\n",
    "                'player2_name': player2_name,\n",
    "                'synergy_score': influence_matrix[i, j]\n",
    "            })\n",
    "\n",
    "# Convert to dataframe\n",
    "synergy_df = pd.DataFrame(synergy_pairs)\n",
    "\n",
    "# Sort by synergy score\n",
    "synergy_df = synergy_df.sort_values('synergy_score', ascending=False)\n",
    "\n",
    "# Display top synergy pairs\n",
    "print(f\"Identified {len(synergy_df)} synergy pairs with score > {synergy_threshold}\")\n",
    "synergy_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify player clusters using community detection\n",
    "# Use the Louvain method for community detection\n",
    "import community as community_louvain\n",
    "\n",
    "# Apply community detection to the influence network\n",
    "partition = community_louvain.best_partition(G_influence)\n",
    "\n",
    "# Count the number of communities\n",
    "n_communities = len(set(partition.values()))\n",
    "print(f\"Identified {n_communities} player communities\")\n",
    "\n",
    "# Group players by community\n",
    "communities = {}\n",
    "for node, community_id in partition.items():\n",
    "    if community_id not in communities:\n",
    "        communities[community_id] = []\n",
    "    \n",
    "    player_id = idx_to_player[node]\n",
    "    player_name = player_names[player_id]\n",
    "    communities[community_id].append(player_name)\n",
    "\n",
    "# Display communities\n",
    "for community_id, players in communities.items():\n",
    "    if len(players) > 3:  # Only show communities with at least 3 players\n",
    "        print(f\"\\nCommunity {community_id} ({len(players)} players):\")\n",
    "        print(\", \".join(players))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the influence network with communities\n",
    "# Extract the largest connected component for better visualization\n",
    "largest_cc = max(nx.connected_components(G_influence), key=len)\n",
    "G_influence_cc = G_influence.subgraph(largest_cc).copy()\n",
    "\n",
    "# Calculate node sizes based on degree centrality\n",
    "degree_centrality = nx.degree_centrality(G_influence_cc)\n",
    "node_sizes = [5000 * degree_centrality[node] + 100 for node in G_influence_cc.nodes()]\n",
    "\n",
    "# Calculate edge widths based on weight\n",
    "edge_widths = [2 * G_influence_cc[u][v]['weight'] for u, v in G_influence_cc.edges()]\n",
    "\n",
    "# Create a spring layout\n",
    "pos = nx.spring_layout(G_influence_cc, seed=42)\n",
    "\n",
    "# Create the visualization with communities\n",
    "plt.figure(figsize=(14, 14))\n",
    "\n",
    "# Get community colors\n",
    "community_colors = {}\n",
    "for node in G_influence_cc.nodes():\n",
    "    community_id = partition.get(node, 0)\n",
    "    if community_id not in community_colors:\n",
    "        community_colors[community_id] = plt.cm.tab20(community_id % 20)\n",
    "\n",
    "# Draw nodes colored by community\n",
    "for community_id in set(partition.values()):\n",
    "    nodes = [node for node in G_influence_cc.nodes() if partition.get(node, 0) == community_id]\n",
    "    nx.draw_networkx_nodes(G_influence_cc, pos, nodelist=nodes, node_size=[node_sizes[list(G_influence_cc.nodes()).index(node)] for node in nodes], \n",
    "                          node_color=[community_colors[community_id]] * len(nodes), alpha=0.8)\n",
    "\n",
    "# Draw edges\n",
    "nx.draw_networkx_edges(G_influence_cc, pos, width=edge_widths, alpha=0.5, edge_color='gray')\n",
    "\n",
    "# Draw labels\n",
    "nx.draw_networkx_labels(G_influence_cc, pos, labels={node: G_influence_cc.nodes[node]['name'] for node in G_influence_cc.nodes()})\n",
    "\n",
    "plt.title('Player Influence Network with Communities', fontsize=16)\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting Synergy Pairs and Clusters\n",
    "\n",
    "Our analysis of synergy pairs and player clusters reveals several interesting patterns:\n",
    "\n",
    "1. **Top Synergy Pairs**: [Observations about top synergy pairs based on your data]\n",
    "   - These pairs show strong positive correlation in performance, suggesting they bring out the best in each other.\n",
    "\n",
    "2. **Player Communities**: [Observations about player communities based on your data]\n",
    "   - Community 1: [Describe the characteristics of this community]\n",
    "   - Community 2: [Describe the characteristics of this community]\n",
    "   - Community 3: [Describe the characteristics of this community]\n",
    "\n",
    "3. **Community Structure**: [Observations about the overall community structure based on your data]\n",
    "\n",
    "These insights can inform lineup construction and player acquisition decisions by identifying players who are likely to work well together and create positive synergies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Dimensional Player Impact\n",
    "\n",
    "Let's integrate production, stability, adaptability, and network metrics to create a comprehensive player impact framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all player metrics\n",
    "# Start with player dynamics\n",
    "player_impact = player_dynamics.copy()\n",
    "\n",
    "# Add team fit metrics\n",
    "player_impact = pd.merge(\n",
    "    player_impact,\n",
    "    player_team_fit[['player_id', 'adaptability_score', 'best_style']],\n",
    "    on='player_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Add network metrics\n",
    "player_impact = pd.merge(\n",
    "    player_impact,\n",
    "    network_df,\n",
    "    on=['player_id', 'player_name'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Fill missing values\n",
    "player_impact = player_impact.fillna(0)\n",
    "\n",
    "# Display the merged data\n",
    "player_impact.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate comprehensive impact score\n",
    "# Normalize metrics for fair comparison\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Select metrics for impact score\n",
    "impact_metrics = ['avg_pts', 'avg_plus_minus', 'system_stability', 'adaptability_score', 'eigenvector_centrality', 'avg_influence']\n",
    "\n",
    "# Create a copy of the data for scaling\n",
    "impact_data = player_impact[impact_metrics].copy()\n",
    "\n",
    "# Invert system_stability (lower is better)\n",
    "impact_data['system_stability'] = -impact_data['system_stability']\n",
    "\n",
    "# Scale the data\n",
    "impact_scaled = scaler.fit_transform(impact_data)\n",
    "\n",
    "# Create a dataframe with scaled metrics\n",
    "impact_scaled_df = pd.DataFrame(impact_scaled, columns=impact_metrics)\n",
    "\n",
    "# Calculate impact score with weights\n",
    "weights = {\n",
    "    'avg_pts': 0.2,\n",
    "    'avg_plus_minus': 0.3,\n",
    "    'system_stability': 0.15,\n",
    "    'adaptability_score': 0.15,\n",
    "    'eigenvector_centrality': 0.1,\n",
    "    'avg_influence': 0.1\n",
    "}\n",
    "\n",
    "impact_score = np.zeros(len(impact_scaled_df))\n",
    "for metric, weight in weights.items():\n",
    "    impact_score += weight * impact_scaled_df[metric]\n",
    "\n",
    "# Add impact score to player impact dataframe\n",
    "player_impact['impact_score'] = impact_score\n",
    "\n",
    "# Sort by impact score\n",
    "player_impact = player_impact.sort_values('impact_score', ascending=False)\n",
    "\n",
    "# Display top players by impact score\n",
    "print(\"Top Players by Comprehensive Impact Score:\")\n",
    "player_impact[['player_name', 'impact_score', 'avg_pts', 'avg_plus_minus', 'system_stability', 'adaptability_score', 'eigenvector_centrality', 'avg_influence']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize impact score components for top players\n",
    "top_players = player_impact.head(10)\n",
    "\n",
    "# Create a radar chart for each player\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.path import Path\n",
    "from matplotlib.spines import Spine\n",
    "from matplotlib.transforms import Affine2D\n",
    "\n",
    "# Radar chart function\n",
    "def radar_chart(ax, angles, values, color, label):\n",
    "    # Plot data\n",
    "    ax.plot(angles, values, 'o-', linewidth=2, color=color, label=label)\n",
    "    # Fill area\n",
    "    ax.fill(angles, values, alpha=0.25, color=color)\n",
    "    # Set y-ticks\n",
    "    ax.set_yticks([0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "    # Set category labels\n",
    "    ax.set_xticks(angles[:-1])\n",
    "    ax.set_xticklabels(categories)\n",
    "    # Add legend\n",
    "    ax.legend(loc='upper right', bbox_to_anchor=(0.1, 0.1))\n",
    "\n",
    "# Categories for the radar chart\n",
    "categories = ['Scoring', 'Impact', 'Stability', 'Adaptability', 'Centrality', 'Influence']\n",
    "# Number of categories\n",
    "N = len(categories)\n",
    "# Angle of each axis\n",
    "angles = [n / float(N) * 2 * np.pi for n in range(N)]\n",
    "angles += angles[:1]  # Close the loop\n",
    "\n",
    "# Create figure\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12), subplot_kw=dict(polar=True))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Colors for each player\n",
    "colors = plt.cm.tab10(np.linspace(0, 1, len(top_players)))\n",
    "\n",
    "# Normalize values for radar chart\n",
    "max_values = {\n",
    "    'avg_pts': top_players['avg_pts'].max(),\n",
    "    'avg_plus_minus': top_players['avg_plus_minus'].max(),\n",
    "    'system_stability': -top_players['system_stability'].min(),  # Invert for radar chart\n",
    "    'adaptability_score': top_players['adaptability_score'].max(),\n",
    "    'eigenvector_centrality': top_players['eigenvector_centrality'].max(),\n",
    "    'avg_influence': top_players['avg_influence'].max()\n",
    "}\n",
    "\n",
    "# Plot each player\n",
    "for i, (_, player) in enumerate(top_players.iterrows()):\n",
    "    if i < 6:  # Only plot the top 6 players\n",
    "        # Get normalized values\n",
    "        values = [\n",
    "            player['avg_pts'] / max_values['avg_pts'],\n",
    "            player['avg_plus_minus'] / max_values['avg_plus_minus'],\n",
    "            -player['system_stability'] / max_values['system_stability'],  # Invert for radar chart\n",
    "            player['adaptability_score'] / max_values['adaptability_score'],\n",
    "            player['eigenvector_centrality'] / max_values['eigenvector_centrality'],\n",
    "            player['avg_influence'] / max_values['avg_influence']\n",
    "        ]\n",
    "        values += values[:1]  # Close the loop\n",
    "        \n",
    "        # Plot radar chart\n",
    "        radar_chart(axes[i], angles, values, colors[i], player['player_name'])\n",
    "        axes[i].set_title(f\"{player['player_name']}\\nImpact Score: {player['impact_score']:.2f}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting Multi-Dimensional Impact\n",
    "\n",
    "Our comprehensive impact framework integrates multiple dimensions of player performance to provide a more complete picture of player value:\n",
    "\n",
    "1. **Top Impact Players**: [Observations about top impact players based on your data]\n",
    "   - These players excel across multiple dimensions, combining production, stability, adaptability, and network influence.\n",
    "\n",
    "2. **Impact Profiles**: [Observations about different impact profiles based on your data]\n",
    "   - Some players derive their value primarily from scoring and traditional production.\n",
    "   - Others contribute through stability, adaptability, or network effects.\n",
    "   - The most valuable players excel in multiple dimensions.\n",
    "\n",
    "3. **Balanced Impact**: [Observations about balanced impact based on your data]\n",
    "   - Players with balanced impact across all dimensions tend to contribute to team success in multiple ways.\n",
    "\n",
    "This multi-dimensional approach provides a more nuanced understanding of player value than traditional statistics alone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traditional vs. Dynamics Comparison\n",
    "\n",
    "Let's compare our dynamics-based player evaluation with traditional methods to identify undervalued and overvalued players."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate traditional player rating\n",
    "player_impact['traditional_rating'] = player_impact['avg_pts'] * 0.7 + player_impact['avg_plus_minus'] * 0.3\n",
    "\n",
    "# Calculate rating difference\n",
    "player_impact['rating_difference'] = player_impact['impact_score'] - (player_impact['traditional_rating'] / player_impact['traditional_rating'].max() * player_impact['impact_score'].max())\n",
    "\n",
    "# Sort by rating difference\n",
    "undervalued = player_impact.nlargest(10, 'rating_difference')\n",
    "overvalued = player_impact.nsmallest(10, 'rating_difference')\n",
    "\n",
    "print(\"Players Most Undervalued by Traditional Metrics:\")\n",
    "print(undervalued[['player_name', 'impact_score', 'traditional_rating', 'rating_difference', 'system_stability', 'adaptability_score', 'eigenvector_centrality']])\n",
    "\n",
    "print(\"\\nPlayers Most Overvalued by Traditional Metrics:\")\n",
    "print(overvalued[['player_name', 'impact_score', 'traditional_rating', 'rating_difference', 'system_stability', 'adaptability_score', 'eigenvector_centrality']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize traditional vs. dynamics-based ratings\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(player_impact['traditional_rating'], player_impact['impact_score'], alpha=0.7)\n",
    "\n",
    "# Add diagonal line\n",
    "max_trad = player_impact['traditional_rating'].max()\n",
    "max_impact = player_impact['impact_score'].max()\n",
    "plt.plot([0, max_trad], [0, max_impact], 'r--', alpha=0.5)\n",
    "\n",
    "# Add labels for notable players\n",
    "for i, row in undervalued.head(5).iterrows():\n",
    "    plt.annotate(row['player_name'], \n",
    "                 (row['traditional_rating'], row['impact_score']),\n",
    "                 fontsize=9, color='green')\n",
    "    \n",
    "for i, row in overvalued.head(5).iterrows():\n",
    "    plt.annotate(row['player_name'], \n",
    "                 (row['traditional_rating'], row['impact_score']),\n",
    "                 fontsize=9, color='red')\n",
    "\n",
    "plt.xlabel('Traditional Rating', fontsize=12)\n",
    "plt.ylabel('Dynamics-Based Impact Score', fontsize=12)\n",
    "plt.title('Traditional vs. Dynamics-Based Player Evaluation', fontsize=14)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Market Inefficiency Opportunities\n",
    "\n",
    "Our comparison of traditional and dynamics-based player evaluation reveals several market inefficiency opportunities:\n",
    "\n",
    "1. **Undervalued Players**: [Observations about undervalued players based on your data]\n",
    "   - These players contribute value through stability, adaptability, and network effects that are not captured by traditional statistics.\n",
    "   - Teams could acquire these players at a discount relative to their true value.\n",
    "\n",
    "2. **Overvalued Players**: [Observations about overvalued players based on your data]\n",
    "   - These players may have impressive traditional statistics but lack stability, adaptability, or positive network effects.\n",
    "   - Teams should be cautious about investing heavily in these players.\n",
    "\n",
    "3. **Value Dimensions**: [Observations about value dimensions based on your data]\n",
    "   - The most undervalued players tend to excel in [specific dimensions based on your data].\n",
    "   - The most overvalued players tend to underperform in [specific dimensions based on your data].\n",
    "\n",
    "These insights can help teams identify players who are likely to outperform or underperform their traditional statistical profiles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Impact Simulation\n",
    "\n",
    "Let's simulate the potential business impact of using our dynamics approach for team improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate team improvement through player acquisition\n",
    "# Select a sample team\n",
    "import random\n",
    "sample_team_id = random.choice(games_processed['Team_ID'].unique())\n",
    "sample_team_name = games_processed[games_processed['Team_ID'] == sample_team_id]['TeamName'].iloc[0]\n",
    "\n",
    "# Get current team players\n",
    "team_players = player_temporal_df[player_temporal_df['Team_ID'] == sample_team_id]['Player_ID'].unique()\n",
    "team_player_names = [player_names.get(player_id, str(player_id)) for player_id in team_players]\n",
    "\n",
    "print(f\"Sample Team: {sample_team_name}\")\n",
    "print(f\"Current Players: {', '.join(team_player_names)}\")\n",
    "\n",
    "# Calculate current team impact\n",
    "current_impact = 0\n",
    "for player_id in team_players:\n",
    "    if player_id in player_to_idx:\n",
    "        player_idx = player_to_idx[player_id]\n",
    "        player_row = player_impact[player_impact['player_id'] == player_id]\n",
    "        if len(player_row) > 0:\n",
    "            current_impact += player_row['impact_score'].iloc[0]\n",
    "\n",
    "print(f\"Current Team Impact: {current_impact:.2f}\")\n",
    "\n",
    "# Identify potential acquisitions\n",
    "potential_acquisitions = []\n",
    "\n",
    "for _, player in undervalued.iterrows():\n",
    "    player_id = player['player_id']\n",
    "    \n",
    "    # Skip players already on the team\n",
    "    if player_id in team_players:\n",
    "        continue\n",
    "    \n",
    "    # Calculate synergy with current team\n",
    "    player_idx = player_to_idx.get(player_id)\n",
    "    if player_idx is not None:\n",
    "        team_synergy = 0\n",
    "        for team_player_id in team_players:\n",
    "            team_player_idx = player_to_idx.get(team_player_id)\n",
    "            if team_player_idx is not None:\n",
    "                team_synergy += influence_matrix[player_idx, team_player_idx]\n",
    "        \n",
    "        # Add to potential acquisitions\n",
    "        potential_acquisitions.append({\n",
    "            'player_id': player_id,\n",
    "            'player_name': player['player_name'],\n",
    "            'impact_score': player['impact_score'],\n",
    "            'traditional_rating': player['traditional_rating'],\n",
    "            'team_synergy': team_synergy,\n",
    "            'total_value': player['impact_score'] + team_synergy\n",
    "        })\n",
    "\n",
    "# Sort by total value\n",
    "acquisition_df = pd.DataFrame(potential_acquisitions)\n",
    "acquisition_df = acquisition_df.sort_values('total_value', ascending=False)\n",
    "\n",
    "# Display top acquisition targets\n",
    "print(f\"\\nTop Acquisition Targets for {sample_team_name}:\")\n",
    "print(acquisition_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate team improvement with optimal acquisitions\n",
    "# Assume we can acquire the top 2 targets\n",
    "top_acquisitions = acquisition_df.head(2)\n",
    "acquisition_impact = top_acquisitions['total_value'].sum()\n",
    "\n",
    "# Calculate new team impact\n",
    "new_impact = current_impact + acquisition_impact\n",
    "improvement = (new_impact / current_impact - 1) * 100\n",
    "\n",
    "print(f\"Current Team Impact: {current_impact:.2f}\")\n",
    "print(f\"New Team Impact: {new_impact:.2f}\")\n",
    "print(f\"Improvement: {improvement:.1f}%\")\n",
    "\n",
    "# Estimate win improvement\n",
    "# Assume a linear relationship between impact and wins\n",
    "# For simplicity, assume 1% impact improvement = 0.5 additional wins\n",
    "win_improvement = improvement * 0.5 / 100 * 82  # 82 games in a season\n",
    "\n",
    "print(f\"Estimated Win Improvement: {win_improvement:.1f} additional wins\")\n",
    "\n",
    "# Estimate financial impact\n",
    "# Assume each win is worth $1.5M in revenue\n",
    "financial_impact = win_improvement * 1.5\n",
    "\n",
    "print(f\"Estimated Financial Impact: ${financial_impact:.1f}M in additional revenue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Impact Insights\n",
    "\n",
    "Our business impact simulation demonstrates the potential value of using our dynamics approach for team improvement:\n",
    "\n",
    "1. **Acquisition Targets**: [Observations about top acquisition targets based on your data]\n",
    "   - These players would provide the greatest impact for [sample_team_name] based on their individual value and synergy with current team members.\n",
    "\n",
    "2. **Performance Improvement**: [Observations about performance improvement based on your data]\n",
    "   - By acquiring these players, [sample_team_name] could improve their team impact by approximately [X]%.\n",
    "   - This translates to an estimated [Y] additional wins per season.\n",
    "\n",
    "3. **Financial Impact**: [Observations about financial impact based on your data]\n",
    "   - The additional wins could generate approximately $[Z]M in additional revenue.\n",
    "   - This represents a significant return on investment for player acquisition.\n",
    "\n",
    "These insights demonstrate the practical business value of our dynamics approach to player evaluation and team construction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applications & Future Work\n",
    "\n",
    "Let's explore potential applications of our dynamics approach and directions for future research."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Game Strategy Recommendations\n",
    "\n",
    "Our dynamics approach can inform game strategy in several ways:\n",
    "\n",
    "1. **Lineup Optimization**: Use stability profiles and synergy pairs to construct lineups that maximize performance.\n",
    "   - Start with high-value stability players as the core.\n",
    "   - Add high-ceiling volatility players strategically.\n",
    "   - Ensure lineup includes players with strong synergy.\n",
    "\n",
    "2. **Matchup Exploitation**: Target opponent weaknesses based on stability patterns.\n",
    "   - Against teams with volatile players, focus on defensive consistency to limit their ceiling.\n",
    "   - Against teams with stable players, use high-ceiling volatility players to create variance.\n",
    "\n",
    "3. **In-Game Adjustments**: Use stability profiles to inform substitution patterns.\n",
    "   - When leading, rely on high-value stability players to maintain the lead.\n",
    "   - When trailing, insert high-ceiling volatility players to change the game dynamic.\n",
    "\n",
    "4. **End-Game Situations**: Use stability profiles to select players for critical moments.\n",
    "   - In close games, rely on players with high stability and positive impact.\n",
    "   - In blowouts, give playing time to players who need development."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Player Acquisition Strategy\n",
    "\n",
    "Our dynamics approach can also inform player acquisition strategy:\n",
    "\n",
    "1. **Target Undervalued Players**: Focus on players who are undervalued by traditional metrics but score highly on our dynamics-based impact score.\n",
    "   - Look for players with high stability, adaptability, and positive network effects.\n",
    "   - Consider team fit and potential synergies with current roster.\n",
    "\n",
    "2. **Avoid Overvalued Players**: Be cautious about players who score highly on traditional metrics but poorly on our dynamics-based impact score.\n",
    "   - Watch out for players with high volatility, low adaptability, or negative network effects.\n",
    "   - Consider whether their playing style fits with the team's system.\n",
    "\n",
    "3. **Balance Roster Construction**: Maintain a balance of stability and volatility in the roster.\n",
    "   - Build around a core of high-value stability players.\n",
    "   - Add high-ceiling volatility players for specific roles.\n",
    "   - Avoid accumulating too many high-risk variability players.\n",
    "\n",
    "4. **Consider Network Effects**: Prioritize players who have positive network effects and can make teammates better.\n",
    "   - Look for players with high eigenvector centrality and positive influence.\n",
    "   - Consider existing synergy pairs when making acquisition decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Future Research Directions\n",
    "\n",
    "There are several promising directions for future research:\n",
    "\n",
    "1. **Spatial Analysis**: Incorporate spatial data to analyze how player performance varies by court region.\n",
    "   - Map stability and volatility patterns across different areas of the court.\n",
    "   - Identify players who excel in specific spatial contexts.\n",
    "\n",
    "2. **Temporal Evolution**: Track stability metrics over time to identify career transition points.\n",
    "   - Analyze how stability profiles evolve throughout a player's career.\n",
    "   - Identify early indicators of performance decline or improvement.\n",
    "\n",
    "3. **Advanced Network Models**: Develop more sophisticated network models to capture complex teammate interactions.\n",
    "   - Incorporate directed influence relationships.\n",
    "   - Model higher-order interactions beyond pairwise relationships.\n",
    "\n",
    "4. **Predictive Modeling**: Develop predictive models for player performance based on stability profiles and network position.\n",
    "   - Forecast how players will perform in new team contexts.\n",
    "   - Predict career trajectories based on stability patterns.\n",
    "\n",
    "5. **Integration with Tracking Data**: Combine our dynamics approach with player tracking data for deeper insights.\n",
    "   - Analyze how movement patterns relate to stability profiles.\n",
    "   - Identify physical indicators of performance consistency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Network Analysis Results\n",
    "\n",
    "Let's save our network analysis results for future reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save player impact data\n",
    "player_impact.to_csv('../data/processed/player_impact.csv', index=False)\n",
    "print(f\"Saved player impact data to ../data/processed/player_impact.csv\")\n",
    "\n",
    "# Save synergy pairs\n",
    "synergy_df.to_csv('../data/processed/synergy_pairs.csv', index=False)\n",
    "print(f\"Saved synergy pairs data to ../data/processed/synergy_pairs.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we've applied network analysis to understand teammate interactions, identify performance multipliers, and develop a comprehensive player impact framework. We've built teammate networks, calculated network metrics, identified synergy pairs and clusters, integrated multiple dimensions of player performance, compared traditional and dynamics-based player evaluation, and simulated the business impact of our approach.\n",
    "\n",
    "Key accomplishments:\n",
    "1. Built teammate networks based on game data and performance correlations\n",
    "print(f\"Current Team Impact: {current_impact:.2f}\")\n",
    "# Add network metrics\n",
    "player_impact = pd.merge(\n",
    "    player_impact,\n",
    "    network_df,\n",
    "    on=['player_id', 'player_name'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Fill missing values\n",
    "player_impact = player_impact.fillna(0)\n",
    "\n",
    "# Display the merged data\n",
    "player_impact.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate comprehensive impact score\n",
    "# Normalize metrics for fair comparison\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Select metrics for impact score\n",
    "impact_metrics = ['avg_pts', 'avg_plus_minus', 'system_stability', 'adaptability_score', 'eigenvector_centrality', 'avg_influence']\n",
    "\n",
    "# Create a copy of the data for scaling\n",
    "impact_data = player_impact[impact_metrics].copy()\n",
    "\n",
    "# Invert system_stability (lower is better)\n",
    "impact_data['system_stability'] = -impact_data['system_stability']\n",
    "\n",
    "# Scale the data\n",
    "impact_scaled = scaler.fit_transform(impact_data)\n",
    "\n",
    "# Create a dataframe with scaled metrics\n",
    "impact_scaled_df = pd.DataFrame(impact_scaled, columns=impact_metrics)\n",
    "\n",
    "# Calculate impact score with weights\n",
    "weights = {\n",
    "    'avg_pts': 0.2,\n",
    "    'avg_plus_minus': 0.3,\n",
    "    'system_stability': 0.15,\n",
    "    'adaptability_score': 0.15,\n",
    "    'eigenvector_centrality': 0.1,\n",
    "    'avg_influence': 0.1\n",
    "}\n",
    "\n",
    "impact_score = np.zeros(len(impact_scaled_df))\n",
    "for metric, weight in weights.items():\n",
    "    impact_score += weight * impact_scaled_df[metric]\n",
    "\n",
    "# Add impact score to player impact dataframe\n",
    "player_impact['impact_score'] = impact_score\n",
    "\n",
    "# Sort by impact score\n",
    "player_impact = player_impact.sort_values('impact_score', ascending=False)\n",
    "\n",
    "# Display top players by impact score\n",
    "print(\"Top Players by Comprehensive Impact Score:\")\n",
    "player_impact[['player_name', 'impact_score', 'avg_pts', 'avg_plus_minus', 'system_stability', 'adaptability_score', 'eigenvector_centrality', 'avg_influence']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize impact score components for top players\n",
    "top_players = player_impact.head(10)\n",
    "\n",
    "# Create a radar chart for each player\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.path import Path\n",
    "from matplotlib.spines import Spine\n",
    "from matplotlib.transforms import Affine2D\n",
    "\n",
    "# Radar chart function\n",
    "def radar_chart(ax, angles, values, color, label):\n",
    "    # Plot data\n",
    "    ax.plot(angles, values, 'o-', linewidth=2, color=color, label=label)\n",
    "    # Fill area\n",
    "    ax.fill(angles, values, alpha=0.25, color=color)\n",
    "    # Set y-ticks\n",
    "    ax.set_yticks([0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "    # Set category labels\n",
    "    ax.set_xticks(angles[:-1])\n",
    "    ax.set_xticklabels(categories)\n",
    "    # Add legend\n",
    "    ax.legend(loc='upper right', bbox_to_anchor=(0.1, 0.1))\n",
    "\n",
    "# Categories for the radar chart\n",
    "categories = ['Scoring', 'Impact', 'Stability', 'Adaptability', 'Centrality', 'Influence']\n",
    "# Number of categories\n",
    "N = len(categories)\n",
    "# Angle of each axis\n",
    "angles = [n / float(N) * 2 * np.pi for n in range(N)]\n",
    "angles += angles[:1]  # Close the loop\n",
    "\n",
    "# Create figure\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12), subplot_kw=dict(polar=True))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Colors for each player\n",
    "colors = plt.cm.tab10(np.linspace(0, 1, len(top_players)))\n",
    "\n",
    "# Normalize values for radar chart\n",
    "max_values = {\n",
    "    'avg_pts': top_players['avg_pts'].max(),\n",
    "    'avg_plus_minus': top_players['avg_plus_minus'].max(),\n",
    "    'system_stability': -top_players['system_stability'].min(),  # Invert for radar chart\n",
    "    'adaptability_score': top_players['adaptability_score'].max(),\n",
    "    'eigenvector_centrality': top_players['eigenvector_centrality'].max(),\n",
    "    'avg_influence': top_players['avg_influence'].max()\n",
    "}\n",
    "\n",
    "# Plot each player\n",
    "for i, (_, player) in enumerate(top_players.iterrows()):\n",
    "    if i < 6:  # Only plot the top 6 players\n",
    "        # Get normalized values\n",
    "        values = [\n",
    "            player['avg_pts'] / max_values['avg_pts'],\n",
    "            player['avg_plus_minus'] / max_values['avg_plus_minus'],\n",
    "            -player['system_stability'] / max_values['system_stability'],  # Invert for radar chart\n",
    "            player['adaptability_score'] / max_values['adaptability_score'],\n",
    "            player['eigenvector_centrality'] / max_values['eigenvector_centrality'],\n",
    "            player['avg_influence'] / max_values['avg_influence']\n",
    "        ]\n",
    "        values += values[:1]  # Close the loop\n",
    "        \n",
    "        # Plot radar chart\n",
    "        radar_chart(axes[i], angles, values, colors[i], player['player_name'])\n",
    "        axes[i].set_title(f\"{player['player_name']}\\nImpact Score: {player['impact_score']:.2f}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting Multi-Dimensional Impact\n",
    "\n",
    "Our comprehensive impact framework integrates multiple dimensions of player performance to provide a more complete picture of player value:\n",
    "\n",
    "1. **Top Impact Players**: [Observations about top impact players based on your data]\n",
    "   - These players excel across multiple dimensions, combining production, stability, adaptability, and network influence.\n",
    "\n",
    "2. **Impact Profiles**: [Observations about different impact profiles based on your data]\n",
    "   - Some players derive their value primarily from scoring and traditional production.\n",
    "   - Others contribute through stability, adaptability, or network effects.\n",
    "   - The most valuable players excel in multiple dimensions.\n",
    "\n",
    "3. **Balanced Impact**: [Observations about balanced impact based on your data]\n",
    "   - Players with balanced impact across all dimensions tend to contribute to team success in multiple ways.\n",
    "\n",
    "This multi-dimensional approach provides a more nuanced understanding of player value than traditional statistics alone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traditional vs. Dynamics Comparison\n",
    "\n",
    "Let's compare our dynamics-based player evaluation with traditional methods to identify undervalued and overvalued players."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate traditional player rating\n",
    "player_impact['traditional_rating'] = player_impact['avg_pts'] * 0.7 + player_impact['avg_plus_minus'] * 0.3\n",
    "\n",
    "# Calculate rating difference\n",
    "player_impact['rating_difference'] = player_impact['impact_score'] - (player_impact['traditional_rating'] / player_impact['traditional_rating'].max() * player_impact['impact_score'].max())\n",
    "\n",
    "# Sort by rating difference\n",
    "undervalued = player_impact.nlargest(10, 'rating_difference')\n",
    "overvalued = player_impact.nsmallest(10, 'rating_difference')\n",
    "\n",
    "print(\"Players Most Undervalued by Traditional Metrics:\")\n",
    "print(undervalued[['player_name', 'impact_score', 'traditional_rating', 'rating_difference', 'system_stability', 'adaptability_score', 'eigenvector_centrality']])\n",
    "\n",
    "print(\"\\nPlayers Most Overvalued by Traditional Metrics:\")\n",
    "print(overvalued[['player_name', 'impact_score', 'traditional_rating', 'rating_difference', 'system_stability', 'adaptability_score', 'eigenvector_centrality']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize traditional vs. dynamics-based ratings\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(player_impact['traditional_rating'], player_impact['impact_score'], alpha=0.7)\n",
    "\n",
    "# Add diagonal line\n",
    "max_trad = player_impact['traditional_rating'].max()\n",
    "max_impact = player_impact['impact_score'].max()\n",
    "plt.plot([0, max_trad], [0, max_impact], 'r--', alpha=0.5)\n",
    "\n",
    "# Add labels for notable players\n",
    "for i, row in undervalued.head(5).iterrows():\n",
    "    plt.annotate(row['player_name'], \n",
    "                 (row['traditional_rating'], row['impact_score']),\n",
    "                 fontsize=9, color='green')\n",
    "    \n",
    "for i, row in overvalued.head(5).iterrows():\n",
    "    plt.annotate(row['player_name'], \n",
    "                 (row['traditional_rating'], row['impact_score']),\n",
    "                 fontsize=9, color='red')\n",
    "\n",
    "plt.xlabel('Traditional Rating', fontsize=12)\n",
    "plt.ylabel('Dynamics-Based Impact Score', fontsize=12)\n",
    "plt.title('Traditional vs. Dynamics-Based Player Evaluation', fontsize=14)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Market Inefficiency Opportunities\n",
    "\n",
    "Our comparison of traditional and dynamics-based player evaluation reveals several market inefficiency opportunities:\n",
    "\n",
    "1. **Undervalued Players**: [Observations about undervalued players based on your data]\n",
    "   - These players contribute value through stability, adaptability, and network effects that are not captured by traditional statistics.\n",
    "   - Teams could acquire these players at a discount relative to their true value.\n",
    "\n",
    "2. **Overvalued Players**: [Observations about overvalued players based on your data]\n",
    "   - These players may have impressive traditional statistics but lack stability, adaptability, or positive network effects.\n",
    "   - Teams should be cautious about investing heavily in these players.\n",
    "\n",
    "3. **Value Dimensions**: [Observations about value dimensions based on your data]\n",
    "   - The most undervalued players tend to excel in [specific dimensions based on your data].\n",
    "   - The most overvalued players tend to underperform in [specific dimensions based on your data].\n",
    "\n",
    "These insights can help teams identify players who are likely to outperform or underperform their traditional statistical profiles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Impact Simulation\n",
    "\n",
    "Let's simulate the potential business impact of using our dynamics approach for team improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate team improvement through player acquisition\n",
    "# Select a sample team\n",
    "import random\n",
    "sample_team_id = random.choice(games_processed['Team_ID'].unique())\n",
    "sample_team_name = games_processed[games_processed['Team_ID'] == sample_team_id]['TeamName'].iloc[0]\n",
    "\n",
    "# Get current team players\n",
    "team_players = player_temporal_df[player_temporal_df['Team_ID'] == sample_team_id]['Player_ID'].unique()\n",
    "team_player_names = [player_names.get(player_id, str(player_id)) for player_id in team_players]\n",
    "\n",
    "print(f\"Sample Team: {sample_team_name}\")\n",
    "print(f\"Current Players: {', '.join(team_player_names)}\")\n",
    "\n",
    "# Calculate current team impact\n",
    "current_impact = 0\n",
    "for player_id in team_players:\n",
    "    if player_id in player_to_idx:\n",
    "        player_idx = player_to_idx[player_id]\n",
    "        player_row = player_impact[player_impact['player_id'] == player_id]\n",
    "        if len(player_row) > 0:\n",
    "            current_impact += player_row['impact_score'].iloc[0]\n",
    "\n",
    "print(f\"Current Team Impact: {current_impact:.2f}\")\n",
    "\n",
    "# Identify potential acquisitions\n",
    "potential_acquisitions = []\n",
    "\n",
    "for _, player in undervalued.iterrows():\n",
    "    player_id = player['player_id']\n",
    "    \n",
    "    # Skip players already on the team\n",
    "    if player_id in team_players:\n",
    "        continue\n",
    "    \n",
    "    # Calculate synergy with current team\n",
    "    player_idx = player_to_idx.get(player_id)\n",
    "    if player_idx is not None:\n",
    "        team_synergy = 0\n",
    "        for team_player_id in team_players:\n",
    "            team_player_idx = player_to_idx.get(team_player_id)\n",
    "            if team_player_idx is not None:\n",
    "                team_synergy += influence_matrix[player_idx, team_player_idx]\n",
    "        \n",
    "        # Add to potential acquisitions\n",
    "        potential_acquisitions.append({\n",
    "            'player_id': player_id,\n",
    "            'player_name': player['player_name'],\n",
    "            'impact_score': player['impact_score'],\n",
    "            'traditional_rating': player['traditional_rating'],\n",
    "            'team_synergy': team_synergy,\n",
    "            'total_value': player['impact_score'] + team_synergy\n",
    "        })\n",
    "\n",
    "# Sort by total value\n",
    "acquisition_df = pd.DataFrame(potential_acquisitions)\n",
    "acquisition_df = acquisition_df.sort_values('total_value', ascending=False)\n",
    "\n",
    "# Display top acquisition targets\n",
    "print(f\"\\nTop Acquisition Targets for {sample_team_name}:\")\n",
    "print(acquisition_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate team improvement with optimal acquisitions\n",
    "# Assume we can acquire the top 2 targets\n",
    "top_acquisitions = acquisition_df.head(2)\n",
    "acquisition_impact = top_acquisitions['total_value'].sum()\n",
    "\n",
    "# Calculate new team impact\n",
    "new_impact = current_impact + acquisition_impact\n",
    "improvement = (new_impact / current_impact - 1) * 100\n",
    "\n",
    "print(f\"Current Team Impact: {current_impact:.2f}\")\n",
    "print(f\"New Team Impact: {new_impact:.2f}\")\n",
    "print(f\"Improvement: {improvement:.1f}%\")\n",
    "\n",
    "# Estimate win improvement\n",
    "# Assume a linear relationship between impact and wins\n",
    "# For simplicity, assume 1% impact improvement = 0.5 additional wins\n",
    "win_improvement = improvement * 0.5 / 100 * 82  # 82 games in a season\n",
    "\n",
    "print(f\"Estimated Win Improvement: {win_improvement:.1f} additional wins\")\n",
    "\n",
    "# Estimate financial impact\n",
    "# Assume each win is worth $1.5M in revenue\n",
    "financial_impact = win_improvement * 1.5\n",
    "\n",
    "print(f\"Estimated Financial Impact: ${financial_impact:.1f}M in additional revenue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Impact Insights\n",
    "\n",
    "Our business impact simulation demonstrates the potential value of using our dynamics approach for team improvement:\n",
    "\n",
    "1. **Acquisition Targets**: [Observations about top acquisition targets based on your data]\n",
    "   - These players would provide the greatest impact for [sample_team_name] based on their individual value and synergy with current team members.\n",
    "\n",
    "2. **Performance Improvement**: [Observations about performance improvement based on your data]\n",
    "   - By acquiring these players, [sample_team_name] could improve their team impact by approximately [X]%.\n",
    "   - This translates to an estimated [Y] additional wins per season.\n",
    "\n",
    "3. **Financial Impact**: [Observations about financial impact based on your data]\n",
    "   - The additional wins could generate approximately $[Z]M in additional revenue.\n",
    "   - This represents a significant return on investment for player acquisition.\n",
    "\n",
    "These insights demonstrate the practical business value of our dynamics approach to player evaluation and team construction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applications & Future Work\n",
    "\n",
    "Let's explore potential applications of our dynamics approach and directions for future research."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Game Strategy Recommendations\n",
    "\n",
    "Our dynamics approach can inform game strategy in several ways:\n",
    "\n",
    "1. **Lineup Optimization**: Use stability profiles and synergy pairs to construct lineups that maximize performance.\n",
    "   - Start with high-value stability players as the core.\n",
    "   - Add high-ceiling volatility players strategically.\n",
    "   - Ensure lineup includes players with strong synergy.\n",
    "\n",
    "2. **Matchup Exploitation**: Target opponent weaknesses based on stability patterns.\n",
    "   - Against teams with volatile players, focus on defensive consistency to limit their ceiling.\n",
    "   - Against teams with stable players, use high-ceiling volatility players to create variance.\n",
    "\n",
    "3. **In-Game Adjustments**: Use stability profiles to inform substitution patterns.\n",
    "   - When leading, rely on high-value stability players to maintain the lead.\n",
    "   - When trailing, insert high-ceiling volatility players to change the game dynamic.\n",
    "\n",
    "4. **End-Game Situations**: Use stability profiles to select players for critical moments.\n",
    "   - In close games, rely on players with high stability and positive impact.\n",
    "   - In blowouts, give playing time to players who need development."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Player Acquisition Strategy\n",
    "\n",
    "Our dynamics approach can also inform player acquisition strategy:\n",
    "\n",
    "1. **Target Undervalued Players**: Focus on players who are undervalued by traditional metrics but score highly on our dynamics-based impact score.\n",
    "   - Look for players with high stability, adaptability, and positive network effects.\n",
    "   - Consider team fit and potential synergies with current roster.\n",
    "\n",
    "2. **Avoid Overvalued Players**: Be cautious about players who score highly on traditional metrics but poorly on our dynamics-based impact score.\n",
    "   - Watch out for players with high volatility, low adaptability, or negative network effects.\n",
    "   - Consider whether their playing style fits with the team's system.\n",
    "\n",
    "3. **Balance Roster Construction**: Maintain a balance of stability and volatility in the roster.\n",
    "   - Build around a core of high-value stability players.\n",
    "   - Add high-ceiling volatility players for specific roles.\n",
    "   - Avoid accumulating too many high-risk variability players.\n",
    "\n",
    "4. **Consider Network Effects**: Prioritize players who have positive network effects and can make teammates better.\n",
    "   - Look for players with high eigenvector centrality and positive influence.\n",
    "   - Consider existing synergy pairs when making acquisition decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Future Research Directions\n",
    "\n",
    "There are several promising directions for future research:\n",
    "\n",
    "1. **Spatial Analysis**: Incorporate spatial data to analyze how player performance varies by court region.\n",
    "   - Map stability and volatility patterns across different areas of the court.\n",
    "   - Identify players who excel in specific spatial contexts.\n",
    "\n",
    "2. **Temporal Evolution**: Track stability metrics over time to identify career transition points.\n",
    "   - Analyze how stability profiles evolve throughout a player's career.\n",
    "   - Identify early indicators of performance decline or improvement.\n",
    "\n",
    "3. **Advanced Network Models**: Develop more sophisticated network models to capture complex teammate interactions.\n",
    "   - Incorporate directed influence relationships.\n",
    "   - Model higher-order interactions beyond pairwise relationships.\n",
    "\n",
    "4. **Predictive Modeling**: Develop predictive models for player performance based on stability profiles and network position.\n",
    "   - Forecast how players will perform in new team contexts.\n",
    "   - Predict career trajectories based on stability patterns.\n",
    "\n",
    "5. **Integration with Tracking Data**: Combine our dynamics approach with player tracking data for deeper insights.\n",
    "   - Analyze how movement patterns relate to stability profiles.\n",
    "   - Identify physical indicators of performance consistency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Network Analysis Results\n",
    "\n",
    "Let's save our network analysis results for future reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save player impact data\n",
    "player_impact.to_csv('../data/processed/player_impact.csv', index=False)\n",
    "print(f\"Saved player impact data to ../data/processed/player_impact.csv\")\n",
    "\n",
    "# Save synergy pairs\n",
    "synergy_df.to_csv('../data/processed/synergy_pairs.csv', index=False)\n",
    "print(f\"Saved synergy pairs data to ../data/processed/synergy_pairs.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we've applied network analysis to understand teammate interactions, identify performance multipliers, and develop a comprehensive player impact framework. We've built teammate networks, calculated network metrics, identified synergy pairs and clusters, integrated multiple dimensions of player performance, compared traditional and dynamics-based player evaluation, and simulated the business impact of our approach.\n",
    "\n",
    "Key accomplishments:\n",
    "1. Built teammate networks based on game data and performance correlations\n",
