{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NBA Player Performance Dynamics: Network Construction and Analysis\n",
    "\n",
    "This notebook applies network analysis to understand teammate interactions in the NBA. We'll build teammate networks, calculate network metrics, and identify synergy pairs and player clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import networkx as nx\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Add the project root to the path so we can import our modules\n",
    "sys.path.append('..')\n",
    "\n",
    "# Import our modules\n",
    "from src.network_analysis import (\n",
    "    build_teammate_network,\n",
    "    calculate_network_metrics,\n",
    "    identify_synergy_pairs\n",
    ")\n",
    "from src.visualization import create_network_visualization\n",
    "from src.utils import setup_plotting_style\n",
    "\n",
    "# Set up plotting style\n",
    "setup_plotting_style()\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Processed Data\n",
    "\n",
    "Let's load the processed data from previous notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the processed data\n",
    "try:\n",
    "    player_dynamics = pd.read_csv('../data/processed/player_dynamics.csv')\n",
    "    player_team_fit = pd.read_csv('../data/processed/player_team_fit.csv')\n",
    "    player_temporal_df = pd.read_csv('../data/processed/player_temporal.csv')\n",
    "    games_processed = pd.read_csv('../data/processed/games_processed.csv')\n",
    "    \n",
    "    # Convert date strings to datetime objects\n",
    "    player_temporal_df['GAME_DATE'] = pd.to_datetime(player_temporal_df['GAME_DATE'])\n",
    "    games_processed['GAME_DATE'] = pd.to_datetime(games_processed['GAME_DATE'])\n",
    "    \n",
    "    print(f\"Loaded player dynamics data with {len(player_dynamics)} players\")\n",
    "    print(f\"Loaded player team fit data with {len(player_team_fit)} players\")\n",
    "    print(f\"Loaded player temporal data with {len(player_temporal_df)} records\")\n",
    "    print(f\"Loaded processed games data with {len(games_processed)} records\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Processed data not found. Please run the previous notebooks first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the player dynamics data\n",
    "player_dynamics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teammate Network Construction\n",
    "\n",
    "Let's build a network of teammate interactions based on game data. We'll create two types of networks:\n",
    "\n",
    "1. **Teammate Frequency Network**: Captures how often players have played together\n",
    "2. **Influence Network**: Captures how players' performances correlate when they play together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify teammates for each game\n",
    "# Group player game data by game and team\n",
    "teammates_by_game = {}\n",
    "\n",
    "for game_id in player_temporal_df['Game_ID'].unique():\n",
    "    game_data = player_temporal_df[player_temporal_df['Game_ID'] == game_id]\n",
    "    \n",
    "    # Group by team\n",
    "    for team_id in game_data['Team_ID'].unique():\n",
    "        team_players = game_data[game_data['Team_ID'] == team_id]\n",
    "        \n",
    "        # Get player IDs\n",
    "        player_ids = team_players['Player_ID'].tolist()\n",
    "        \n",
    "        # Add to teammates dictionary\n",
    "        if game_id not in teammates_by_game:\n",
    "            teammates_by_game[game_id] = {}\n",
    "        \n",
    "        teammates_by_game[game_id][team_id] = player_ids\n",
    "\n",
    "# Count number of games with teammate data\n",
    "print(f\"Identified teammates for {len(teammates_by_game)} games\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build teammate frequency matrix\n",
    "player_ids = player_dynamics['player_id'].unique()\n",
    "n_players = len(player_ids)\n",
    "\n",
    "# Create a dictionary to map player IDs to indices\n",
    "player_to_idx = {player_id: i for i, player_id in enumerate(player_ids)}\n",
    "idx_to_player = {i: player_id for i, player_id in enumerate(player_ids)}\n",
    "\n",
    "# Initialize teammate frequency matrix\n",
    "teammate_freq = np.zeros((n_players, n_players))\n",
    "\n",
    "# Fill the matrix\n",
    "for game_id, teams in teammates_by_game.items():\n",
    "    for team_id, players in teams.items():\n",
    "        # For each pair of teammates\n",
    "        for i, player1 in enumerate(players):\n",
    "            if player1 in player_to_idx:  # Check if player is in our player list\n",
    "                idx1 = player_to_idx[player1]\n",
    "                for player2 in players[i+1:]:\n",
    "                    if player2 in player_to_idx:  # Check if player is in our player list\n",
    "                        idx2 = player_to_idx[player2]\n",
    "                        # Increment frequency for both directions\n",
    "                        teammate_freq[idx1, idx2] += 1\n",
    "                        teammate_freq[idx2, idx1] += 1\n",
    "\n",
    "# Create a dataframe with player names for easier interpretation\n",
    "player_names = {}\n",
    "for player_id in player_ids:\n",
    "    player_name = player_dynamics[player_dynamics['player_id'] == player_id]['player_name'].iloc[0]\n",
    "    player_names[player_id] = player_name\n",
    "\n",
    "# Print some statistics about the teammate frequency matrix\n",
    "print(f\"Teammate frequency matrix shape: {teammate_freq.shape}\")\n",
    "print(f\"Maximum teammate frequency: {np.max(teammate_freq)}\")\n",
    "print(f\"Average teammate frequency: {np.mean(teammate_freq)}\")\n",
    "print(f\"Number of non-zero entries: {np.count_nonzero(teammate_freq)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build correlation-based influence network\n",
    "# For each pair of teammates, calculate the correlation between their plus/minus\n",
    "influence_matrix = np.zeros((n_players, n_players))\n",
    "\n",
    "# For each player pair\n",
    "for i in range(n_players):\n",
    "    player1_id = idx_to_player[i]\n",
    "    player1_games = player_temporal_df[player_temporal_df['Player_ID'] == player1_id]\n",
    "    \n",
    "    for j in range(i+1, n_players):\n",
    "        player2_id = idx_to_player[j]\n",
    "        player2_games = player_temporal_df[player_temporal_df['Player_ID'] == player2_id]\n",
    "        \n",
    "        # Find common games\n",
    "        common_games = set(player1_games['Game_ID']).intersection(set(player2_games['Game_ID']))\n",
    "        \n",
    "        # If they have enough common games\n",
    "        if len(common_games) >= 10:  # Minimum number of common games\n",
    "            # Get plus/minus for common games\n",
    "            player1_pm = player1_games[player1_games['Game_ID'].isin(common_games)]['PLUS_MINUS'].values\n",
    "            player2_pm = player2_games[player2_games['Game_ID'].isin(common_games)]['PLUS_MINUS'].values\n",
    "            \n",
    "            # Calculate correlation\n",
    "            corr = np.corrcoef(player1_pm, player2_pm)[0, 1]\n",
    "            \n",
    "            # Store correlation in influence matrix\n",
    "            influence_matrix[i, j] = corr\n",
    "            influence_matrix[j, i] = corr\n",
    "\n",
    "# Replace NaN values with 0\n",
    "influence_matrix = np.nan_to_num(influence_matrix)\n",
    "\n",
    "# Print some statistics about the influence matrix\n",
    "print(f\"Influence matrix shape: {influence_matrix.shape}\")\n",
    "print(f\"Maximum influence: {np.max(influence_matrix)}\")\n",
    "print(f\"Minimum influence: {np.min(influence_matrix)}\")\n",
    "print(f\"Average influence: {np.mean(influence_matrix)}\")\n",
    "print(f\"Number of non-zero entries: {np.count_nonzero(influence_matrix)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Visualization\n",
    "\n",
    "Let's visualize the teammate networks to understand the structure of player interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create network visualizations\n",
    "# Convert matrices to NetworkX graphs\n",
    "# Teammate frequency network\n",
    "G_freq = nx.Graph()\n",
    "\n",
    "# Add nodes\n",
    "for i in range(n_players):\n",
    "    player_id = idx_to_player[i]\n",
    "    player_name = player_names[player_id]\n",
    "    G_freq.add_node(i, name=player_name, id=player_id)\n",
    "\n",
    "# Add edges with weight based on frequency\n",
    "for i in range(n_players):\n",
    "    for j in range(i+1, n_players):\n",
    "        if teammate_freq[i, j] > 0:  # Only add edges for players who have been teammates\n",
    "            G_freq.add_edge(i, j, weight=teammate_freq[i, j])\n",
    "\n",
    "# Influence network\n",
    "G_influence = nx.Graph()\n",
    "\n",
    "# Add nodes\n",
    "for i in range(n_players):\n",
    "    player_id = idx_to_player[i]\n",
    "    player_name = player_names[player_id]\n",
    "    G_influence.add_node(i, name=player_name, id=player_id)\n",
    "\n",
    "# Add edges with weight based on influence\n",
    "for i in range(n_players):\n",
    "    for j in range(i+1, n_players):\n",
    "        if influence_matrix[i, j] > 0.3:  # Only add edges for significant positive influence\n",
    "            G_influence.add_edge(i, j, weight=influence_matrix[i, j])\n",
    "\n",
    "# Print network statistics\n",
    "print(f\"Teammate frequency network: {G_freq.number_of_nodes()} nodes, {G_freq.number_of_edges()} edges\")\n",
    "print(f\"Influence network: {G_influence.number_of_nodes()} nodes, {G_influence.number_of_edges()} edges\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the influence network\n",
    "# Extract the largest connected component for better visualization\n",
    "largest_cc = max(nx.connected_components(G_influence), key=len)\n",
    "G_influence_cc = G_influence.subgraph(largest_cc).copy()\n",
    "\n",
    "# Calculate node sizes based on degree centrality\n",
    "degree_centrality = nx.degree_centrality(G_influence_cc)\n",
    "node_sizes = [5000 * degree_centrality[node] + 100 for node in G_influence_cc.nodes()]\n",
    "\n",
    "# Calculate edge widths based on weight\n",
    "edge_widths = [2 * G_influence_cc[u][v]['weight'] for u, v in G_influence_cc.edges()]\n",
    "\n",
    "# Create a spring layout\n",
    "pos = nx.spring_layout(G_influence_cc, seed=42)\n",
    "\n",
    "# Create the visualization\n",
    "plt.figure(figsize=(12, 12))\n",
    "nx.draw_networkx_nodes(G_influence_cc, pos, node_size=node_sizes, alpha=0.7, node_color='skyblue')\n",
    "nx.draw_networkx_edges(G_influence_cc, pos, width=edge_widths, alpha=0.5, edge_color='gray')\n",
    "nx.draw_networkx_labels(G_influence_cc, pos, labels={node: G_influence_cc.nodes[node]['name'] for node in G_influence_cc.nodes()})\n",
    "\n",
    "plt.title('Player Influence Network (Largest Connected Component)', fontsize=14)\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting the Teammate Network\n",
    "\n",
    "The teammate network visualization reveals several interesting patterns:\n",
    "\n",
    "1. **Network Structure**: The network shows clusters of players who frequently play together, typically representing team cores and common lineups.\n",
    "\n",
    "2. **Central Players**: Players with high degree centrality (larger nodes) are those who have played with many different teammates, often indicating veterans who have been on multiple teams or players who are frequently part of different lineup combinations.\n",
    "\n",
    "3. **Player Clusters**: Distinct clusters in the network typically represent team units or players who have strong on-court chemistry.\n",
    "\n",
    "4. **Influence Relationships**: The thickness of edges represents the strength of performance correlation between players, with thicker edges indicating stronger positive influence.\n",
    "\n",
    "These patterns provide insights into the social and performance dynamics of NBA teams, highlighting players who serve as connectors, influencers, or performance multipliers within the league."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Metrics Calculation\n",
    "\n",
    "Let's calculate network metrics to quantify player influence and centrality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate network metrics for each player\n",
    "network_metrics = []\n",
    "\n",
    "# Calculate centrality metrics for the influence network\n",
    "degree_centrality = nx.degree_centrality(G_influence)\n",
    "betweenness_centrality = nx.betweenness_centrality(G_influence)\n",
    "eigenvector_centrality = nx.eigenvector_centrality_numpy(G_influence, weight='weight')\n",
    "pagerank = nx.pagerank(G_influence, weight='weight')\n",
    "\n",
    "# Calculate average influence\n",
    "avg_influence = {}\n",
    "for i in range(n_players):\n",
    "    # Get non-zero influences\n",
    "    influences = influence_matrix[i, :]\n",
    "    non_zero = influences[influences != 0]\n",
    "    if len(non_zero) > 0:\n",
    "        avg_influence[i] = np.mean(non_zero)\n",
    "    else:\n",
    "        avg_influence[i] = 0\n",
    "\n",
    "# Calculate positive influence count\n",
    "positive_influence_count = {}\n",
    "for i in range(n_players):\n",
    "    positive_influence_count[i] = np.sum(influence_matrix[i, :] > 0.3)  # Count significant positive influences\n",
    "\n",
    "# Combine metrics for each player\n",
    "for i in range(n_players):\n",
    "    player_id = idx_to_player[i]\n",
    "    player_name = player_names[player_id]\n",
    "    \n",
    "    network_metrics.append({\n",
    "        'player_id': player_id,\n",
    "        'player_name': player_name,\n",
    "        'degree_centrality': degree_centrality.get(i, 0),\n",
    "        'betweenness_centrality': betweenness_centrality.get(i, 0),\n",
    "        'eigenvector_centrality': eigenvector_centrality.get(i, 0),\n",
    "        'pagerank': pagerank.get(i, 0),\n",
    "        'avg_influence': avg_influence.get(i, 0),\n",
    "        'positive_influence_count': positive_influence_count.get(i, 0)\n",
    "    })\n",
    "\n",
    "# Convert to dataframe\n",
    "network_df = pd.DataFrame(network_metrics)\n",
    "\n",
    "# Sort by eigenvector centrality\n",
    "network_df = network_df.sort_values('eigenvector_centrality', ascending=False)\n",
    "\n",
    "# Display top players by network metrics\n",
    "network_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize network metrics distribution\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Degree centrality\n",
    "axes[0, 0].hist(network_df['degree_centrality'], bins=20, alpha=0.7, color='skyblue')\n",
    "axes[0, 0].set_xlabel('Degree Centrality', fontsize=12)\n",
    "axes[0, 0].set_ylabel('Number of Players', fontsize=12)\n",
    "axes[0, 0].set_title('Degree Centrality Distribution', fontsize=14)\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Eigenvector centrality\n",
    "axes[0, 1].hist(network_df['eigenvector_centrality'], bins=20, alpha=0.7, color='salmon')\n",
    "axes[0, 1].set_xlabel('Eigenvector Centrality', fontsize=12)\n",
    "axes[0, 1].set_ylabel('Number of Players', fontsize=12)\n",
    "axes[0, 1].set_title('Eigenvector Centrality Distribution', fontsize=14)\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Average influence\n",
    "axes[1, 0].hist(network_df['avg_influence'], bins=20, alpha=0.7, color='lightgreen')\n",
    "axes[1, 0].set_xlabel('Average Influence', fontsize=12)\n",
    "axes[1, 0].set_ylabel('Number of Players', fontsize=12)\n",
    "axes[1, 0].set_title('Average Influence Distribution', fontsize=14)\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Positive influence count\n",
    "axes[1, 1].hist(network_df['positive_influence_count'], bins=20, alpha=0.7, color='purple')\n",
    "axes[1, 1].set_xlabel('Positive Influence Count', fontsize=12)\n",
    "axes[1, 1].set_ylabel('Number of Players', fontsize=12)\n",
    "axes[1, 1].set_title('Positive Influence Count Distribution', fontsize=14)\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify top players by different network metrics\n",
    "top_degree = network_df.nlargest(5, 'degree_centrality')\n",
    "top_eigenvector = network_df.nlargest(5, 'eigenvector_centrality')\n",
    "top_betweenness = network_df.nlargest(5, 'betweenness_centrality')\n",
    "top_influence = network_df.nlargest(5, 'avg_influence')\n",
    "\n",
    "print(\"Top Players by Degree Centrality (Connectivity):\")\n",
    "print(top_degree[['player_name', 'degree_centrality']])\n",
    "\n",
    "print(\"\\nTop Players by Eigenvector Centrality (Influence):\")\n",
    "print(top_eigenvector[['player_name', 'eigenvector_centrality']])\n",
    "\n",
    "print(\"\\nTop Players by Betweenness Centrality (Bridge Players):\")\n",
    "print(top_betweenness[['player_name', 'betweenness_centrality']])\n",
    "\n",
    "print(\"\\nTop Players by Average Influence:\")\n",
    "print(top_influence[['player_name', 'avg_influence']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting Network Metrics\n",
    "\n",
    "The network metrics provide insights into different aspects of player influence and connectivity:\n",
    "\n",
    "1. **Degree Centrality**: Measures the number of direct connections a player has. Players with high degree centrality are well-connected and have played with many different teammates.\n",
    "   - Top players: [List top players from your data]\n",
    "\n",
    "2. **Eigenvector Centrality**: Measures influence by considering both the quantity and quality of connections. Players with high eigenvector centrality are connected to other influential players.\n",
    "   - Top players: [List top players from your data]\n",
    "\n",
    "3. **Betweenness Centrality**: Measures how often a player serves as a bridge between other players. Players with high betweenness centrality connect different groups or clusters of players.\n",
    "   - Top players: [List top players from your data]\n",
    "\n",
    "4. **Average Influence**: Measures the average correlation in plus/minus with teammates. Players with high average influence tend to have a positive impact on their teammates' performance.\n",
    "   - Top players: [List top players from your data]\n",
    "\n",
    "These metrics identify different types of influential players in the NBA, from connectors to performance multipliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify Synergy Pairs and Clusters\n",
    "\n",
    "Let's identify player pairs with strong synergy and clusters of players who work well together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify synergy pairs\n",
    "synergy_pairs = []\n",
    "\n",
    "# Threshold for significant synergy\n",
    "synergy_threshold = 0.5\n",
    "\n",
    "for i in range(n_players):\n",
    "    for j in range(i+1, n_players):\n",
    "        if influence_matrix[i, j] > synergy_threshold:  # Only consider strong positive influence\n",
    "            player1_id = idx_to_player[i]\n",
    "            player2_id = idx_to_player[j]\n",
    "            player1_name = player_names[player1_id]\n",
    "            player2_name = player_names[player2_id]\n",
    "            \n",
    "            synergy_pairs.append({\n",
    "                'player1_id': player1_id,\n",
    "                'player2_id': player2_id,\n",
    "                'player1_name': player1_name,\n",
    "                'player2_name': player2_name,\n",
    "                'synergy_score': influence_matrix[i, j]\n",
    "            })\n",
    "\n",
    "# Convert to dataframe\n",
    "synergy_df = pd.DataFrame(synergy_pairs)\n",
    "\n",
    "# Sort by synergy score\n",
    "synergy_df = synergy_df.sort_values('synergy_score', ascending=False)\n",
    "\n",
    "# Display top synergy pairs\n",
    "print(f\"Identified {len(synergy_df)} synergy pairs with score > {synergy_threshold}\")\n",
    "synergy_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify player clusters using community detection\n",
    "# Use the Louvain method for community detection\n",
    "import community as community_louvain\n",
    "\n",
    "# Apply community detection to the influence network\n",
    "partition = community_louvain.best_partition(G_influence)\n",
    "\n",
    "# Count the number of communities\n",
    "n_communities = len(set(partition.values()))\n",
    "print(f\"Identified {n_communities} player communities\")\n",
    "\n",
    "# Group players by community\n",
    "communities = {}\n",
    "for node, community_id in partition.items():\n",
    "    if community_id not in communities:\n",
    "        communities[community_id] = []\n",
    "    \n",
    "    player_id = idx_to_player[node]\n",
    "    player_name = player_names[player_id]\n",
    "    communities[community_id].append(player_name)\n",
    "\n",
    "# Display communities\n",
    "for community_id, players in communities.items():\n",
    "    if len(players) > 3:  # Only show communities with at least 3 players\n",
    "        print(f\"\\nCommunity {community_id} ({len(players)} players):\")\n",
    "        print(\", \".join(players))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the influence network with communities\n",
    "# Extract the largest connected component for better visualization\n",
    "largest_cc = max(nx.connected_components(G_influence), key=len)\n",
    "G_influence_cc = G_influence.subgraph(largest_cc).copy()\n",
    "\n",
    "# Calculate node sizes based on degree centrality\n",
    "degree_centrality = nx.degree_centrality(G_influence_cc)\n",
    "node_sizes = [5000 * degree_centrality[node] + 100 for node in G_influence_cc.nodes()]\n",
    "\n",
    "# Calculate edge widths based on weight\n",
    "edge_widths = [2 * G_influence_cc[u][v]['weight'] for u, v in G_influence_cc.edges()]\n",
    "\n",
    "# Create a spring layout\n",
    "pos = nx.spring_layout(G_influence_cc, seed=42)\n",
    "\n",
    "# Create the visualization with communities\n",
    "plt.figure(figsize=(14, 14))\n",
    "\n",
    "# Get community colors\n",
    "community_colors = {}\n",
    "for node in G_influence_cc.nodes():\n",
    "    community_id = partition.get(node, 0)\n",
    "    if community_id not in community_colors:\n",
    "        community_colors[community_id] = plt.cm.tab20(community_id % 20)\n",
    "\n",
    "# Draw nodes colored by community\n",
    "for community_id in set(partition.values()):\n",
    "    nodes = [node for node in G_influence_cc.nodes() if partition.get(node, 0) == community_id]\n",
    "    nx.draw_networkx_nodes(G_influence_cc, pos, nodelist=nodes, node_size=[node_sizes[list(G_influence_cc.nodes()).index(node)] for node in nodes], \n",
    "                          node_color=[community_colors[community_id]] * len(nodes), alpha=0.8)\n",
    "\n",
    "# Draw edges\n",
    "nx.draw_networkx_edges(G_influence_cc, pos, width=edge_widths, alpha=0.5, edge_color='gray')\n",
    "\n",
    "# Draw labels\n",
    "nx.draw_networkx_labels(G_influence_cc, pos, labels={node: G_influence_cc.nodes[node]['name'] for node in G_influence_cc.nodes()})\n",
    "\n",
    "plt.title('Player Influence Network with Communities', fontsize=16)\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting Synergy Pairs and Clusters\n",
    "\n",
    "Our analysis of synergy pairs and player clusters reveals several interesting patterns:\n",
    "\n",
    "1. **Top Synergy Pairs**: The pairs with the highest synergy scores represent players who consistently perform well together. These pairs often share complementary skills or have developed strong on-court chemistry.\n",
    "\n",
    "2. **Player Communities**: The community detection algorithm has identified natural groupings of players who have positive performance correlations. These communities often represent:\n",
    "   - Players from the same team who frequently play together\n",
    "   - Players with compatible playing styles\n",
    "   - Players who have moved between teams but maintained connections\n",
    "\n",
    "3. **Community Structure**: The overall community structure provides insights into the social and performance networks within the NBA, highlighting how player performance is interconnected across teams and playing styles.\n",
    "\n",
    "These insights can inform lineup construction and player acquisition decisions by identifying players who are likely to work well together and create positive synergies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Network Analysis Results\n",
    "\n",
    "Let's save our network analysis results for use in the next notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save network metrics\n",
    "network_df.to_csv('../data/processed/network_metrics.csv', index=False)\n",
    "print(f\"Saved network metrics to ../data/processed/network_metrics.csv\")\n",
    "\n",
    "# Save synergy pairs\n",
    "synergy_df.to_csv('../data/processed/synergy_pairs.csv', index=False)\n",
    "print(f\"Saved synergy pairs to ../data/processed/synergy_pairs.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we've applied network analysis to understand teammate interactions in the NBA. We've built teammate networks, calculated network metrics, and identified synergy pairs and player clusters.\n",
    "\n",
    "Key accomplishments:\n",
    "1. Built teammate frequency and influence networks based on game data\n",
    "2. Visualized the network structure to identify key patterns and relationships\n",
    "3. Calculated network metrics including centrality and influence measures\n",
    "4. Identified synergy pairs with strong positive performance correlations\n",
    "5. Detected player communities using community detection algorithms\n",
    "\n",
    "These network insights provide a deeper understanding of the social and performance dynamics in the NBA, revealing patterns that are invisible to traditional statistics. In the next notebook (05b_player_impact.ipynb), we'll build on these network insights to develop a comprehensive player impact framework that integrates production, stability, adaptability, and network metrics."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}